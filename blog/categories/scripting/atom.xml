<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Scripting | mattmakesmaps]]></title>
  <link href="http://mkgeomatics.github.io/blog/categories/scripting/atom.xml" rel="self"/>
  <link href="http://mkgeomatics.github.io/"/>
  <updated>2013-04-28T11:22:37-07:00</updated>
  <id>http://mkgeomatics.github.io/</id>
  <author>
    <name><![CDATA[Matthew Kenny]]></name>
    <email><![CDATA[matthewkenny AT gmail DOT com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PL/pgSQL function to Iterate pgRouting]]></title>
    <link href="http://mkgeomatics.github.io/blog/2010/06/28/plpgsql-function-to-iterate-pgrouting/"/>
    <updated>2010-06-28T00:37:39-07:00</updated>
    <id>http://mkgeomatics.github.io/blog/2010/06/28/plpgsql-function-to-iterate-pgrouting</id>
    <content type="html"><![CDATA[<p>I've been working on a side project using <a href="http://www.mkgeomatics.com/wordpress/?s=pgRouting&amp;searchsubmit=Find">pgRouting</a> to determine the least-cost path across a street network from a given building to the nearest bus stop within <a href="http://en.wikipedia.org/wiki/Bellingham,_Washington">Bellingham, WA</a>. It's one thing to execute pgRouting's built-in functions for a single vertex (building) to another vertex (bus stop)... but another to have the function iterate through all buildings and their closest bus stop.</p>

<p>So that began my first experience with using PL/pgSQL. The benefit for using the procedural language for PostgreSQL lies in its ability to loop through collections of records easily. I've posted my function below. It's not pretty, but it's filled with enough notices to let me know where an error occurs, which helped me understand how things were acting each step of the way. Here is the basic idea:</p>

<ul>
<li><p>Loop through a table in which each row has a source and destination vertex</p></li>
<li><p>Execute the pgRouting function using these two vertices, determining the length of the least-cost path.</p></li>
<li><p>Populate a field, 'dist_calc' with the distance.</p></li>
</ul>


<p>[sourcecode]
CREATE OR REPLACE FUNCTION bulk_route_generate() RETURNS VOID AS $$
DECLARE
 bld_row bld_wtastops_staging5%ROWTYPE;
 dist_calc RECORD;
BEGIN
 RAISE NOTICE 'Beginning Function';
 FOR bld_row IN SELECT * FROM bld_wtastops_staging5 WHERE bld_wtastops_staging5.bld_vert_node IS NOT NULL
 AND bld_wtastops_staging5.wtastops_vert_node IS NOT NULL
 -- BEGIN ADDING BUM NODES TO SKIP OVER
 AND bld_wtastops_staging5.bld_vert_node &lt;&gt; 2915
 AND bld_wtastops_staging5.wtastops_vert_node &lt;&gt; 293
 -- ADD START GID
 -- USED ONLY IF BUM NODES EXIST
 --AND bld_wtastops_staging5.bld_gid &gt;= 29200
 ORDER BY bld_wtastops_staging5.bld_gid LOOP
 RAISE NOTICE 'Value of wtastops_vert_node is %. The value of bld_vert_node is %',bld_row.wtastops_vert_node, bld_row.bld_vert_node;
 RAISE NOTICE 'Value of wtastops_gid is %. The value of bld_gid is %',bld_row.wtastops_gid, bld_row.bld_gid;
 -- BEGIN STANDARD pgRouting A*Star FUNCTION
 SELECT SUM(cost) INTO dist_calc FROM shortest_path_astar('
 SELECT gid as id,
 source::integer,
 target::integer,
 length::double precision as cost,
 x1, y1, x2, y2
 FROM streets_9102748',
 bld_row.bld_vert_node, bld_row.wtastops_vert_node, false, false);
 RAISE NOTICE 'Value of dist_calc is %.',dist_calc;
 EXECUTE 'UPDATE bld_wtastops_staging5
 SET route_dist = ' ||dist_calc|| '
 WHERE ' ||bld_row.bld_gid|| ' = bld_wtastops_staging5.bld_gid';
 END LOOP;
 -- BAIL OUT ON ERRORS
 EXCEPTION
 WHEN CONTAINING_SQL_NOT_PERMITTED THEN
 RAISE NOTICE ' EXECPTION Value of wtastops_vert_node is %. The value of bld_vert_node is %',bld_row.wtastops_vert_node, bld_row.bld_vert_node;
END;
$$ LANGUAGE 'plpgsql';
-- EXECUTE FUNCTION
SELECT bulk_route_generate();
[/sourcecode]</p>

<p>I'm excited at the possibilities that using PL/pgSQL offers in terms of manipulating data. I'm sure that the above function can be cleaned up quite a bit, too. If I ever have the need to re-visit this or similar problems, I'll be sure to do some serious head-scratching to think about a better approach!</p>

<p>Here is an image of the resulting data generated using <a href="http://mapnik.org/">mapnik</a>. Areas from dark green to light-green are within a 1/4 mile distance, while areas from yellow-to-red represent distances increasingly greater then a 1/4 mile. The large checkered areas are where the dataset failed to route. More on that at another time.</p>

<p>[caption id="attachment_360" align="alignnone" width="430" caption="the result as seen in mapnik"]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/06/bld_sym_diverging_web.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/06/bld_sym_diverging_web.png" alt="bld_sym_diverging_web" /></a>[/caption]</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nested Tuples and Hours of Patience]]></title>
    <link href="http://mkgeomatics.github.io/blog/2008/10/03/nested-tuples-and-hours-of-patience/"/>
    <updated>2008-10-03T14:48:38-07:00</updated>
    <id>http://mkgeomatics.github.io/blog/2008/10/03/nested-tuples-and-hours-of-patience</id>
    <content type="html"><![CDATA[<p>I've finally got a working python script that does the following:</p>

<p>-Reads each of the vertexes of a polyline shapefile using 'OGR'</p>

<p>-Runs the vertexes through the Douglas-Peucker smoothing algorithm.</p>

<p>-Generates an output text file using 'stdout' with the resulting 'smoothed' coordinates (in whatever linear unit of measurement that the source shapefile happens to be in).</p>

<p>This has taken quite awhile to get this far, but it has been an excellent learning experience. The breakthrough for tonight was understanding that the Douglas-Peucker algorithm which I downloaded from mappinghacks required a nested tuple as an input. Basically then, I needed to figure out how translate the extracted vertexes from the source shapefile into the tuple object.</p>

<p>Things started to go bad, really bad, when I attempted to create formatted output files for the extracted vertexes... and re-import them as input files for the DP algorithm. It's all good now though, and the code looks (a bit) cleaner.</p>

<p>The next step will be to take this output text file and build another shapefile from it...</p>

<p>Here is a link to the heavily commented <a href="http://www.mkgeomatics.com/scripts/dp_100308.py">script</a> (right-click, select 'save-as') as it stands thus-far.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I'm Obsessed With Douglas-Peucker]]></title>
    <link href="http://mkgeomatics.github.io/blog/2008/09/30/im-obsessed-with-douglas-peucker/"/>
    <updated>2008-09-30T08:12:46-07:00</updated>
    <id>http://mkgeomatics.github.io/blog/2008/09/30/im-obsessed-with-douglas-peucker</id>
    <content type="html"><![CDATA[<p>The Problem: Web map vector overlays take a really long time to load if there are too many verticies.</p>

<p>The Idea: Use the Douglas-Peucker algorithm to reduce the number of verticies thereby decreasing load time.</p>

<p>The [Proposed] Solution: Using a version of the Douglas-Peucker algorithm written in Python, input a source shapefile, and output a smoothed shapefile through the following steps. This script currently uses board coordinates, and as such, is not 'spatially' enabled. The trick is to make it except shapefiles as an input source.</p>

<p>-Extract each of the verticies using ogrinfo, pipe to grep, and export to output csv file.
$ogrinfo -al input_polyline.shp | grep linestring | tr -d "LINESTRING()" > output.csv</p>

<p>-Reformat the verticies [somehow], so that they can be readable to the python script.</p>

<p>-Rebuild shapefile from output csv with projection information using GDAL/OGR.</p>

<p>So my plan is to essentially to break down the shapefile, smooth it, and build it back up again, using open source tools. We'll see how far this goes.</p>

<p>Some reading:</p>

<p><a href="http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm">Douglas-Peucker Algorithm</a></p>

<p><a href="http://users.ox.ac.uk/~orie1848/tutorial.html">Existing GRASS Implementation</a></p>

<p><a href="http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?id=530&amp;pid=513&amp;topicname=Simplifying_and_smoothing_features">Existing ArcGIS Implementation</a></p>

<p>-</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python GP Strangeness]]></title>
    <link href="http://mkgeomatics.github.io/blog/2008/09/14/python-gp-strangeness/"/>
    <updated>2008-09-14T09:11:44-07:00</updated>
    <id>http://mkgeomatics.github.io/blog/2008/09/14/python-gp-strangeness</id>
    <content type="html"><![CDATA[<p>I had to explicitly set the workspace, list the ASCII files, THEN link the two into a single variable for use in the ASCIIToRaster tool. I could have sworn that all I needed to do was to pass along the ASCII variable right into the ASCIIToRaster tool, and it would automatically carry the file path along with it. Maybe that is only the case when you are working with fields, rather than rasters / feature classes?</p>

<h1>Batch Convert ASCII to ESRI GRID</h1>

<h1>Matthew Kenny</h1>

<h1>September 14, 2008</h1>

<h6>#</h6>

<h1>Import the arcgisscripting module</h1>

<p>import sys, arcgisscripting</p>

<h1>Create the Geoprocessor object</h1>

<p>gp = arcgisscripting.create()</p>

<h1>Set the workspace</h1>

<p>gp.workspace = ("F:/!South_Kona/DEM_XYZ_Tiled/Area1/Group5/ASCII/")</p>

<h1>get list of all the ASCII files in the workspace</h1>

<p>asciiList = gp.ListRasters("<em>DEM</em>", "*")
ascii = asciiList.next()
print "Starting with " + ascii</p>

<h1>Set initial INPUT file</h1>

<p>inputAscii = gp.workspace + "/" + ascii
print inputAscii</p>

<h1>Set initial OUTPUT file</h1>

<p>raster = gp.workspace + "/GRID/" + ascii[:-8] + ".img"
print raster</p>

<h1>loop through list of feature classes</h1>

<p>while ascii:</p>

<h1>Execute ASCII to Raster</h1>

<p>    gp.ASCIIToRaster_conversion(inputAscii, raster, "INTEGER")
    print "File " + raster+ " has been created."
    ascii = asciiList.next()
    print "Moving onto " + ascii
    inputAscii = gp.workspace + "/" + ascii
    print "new inputAscii: " + inputAscii
    raster = gp.workspace + "/GRID/" + ascii[:-8] + ".img"
    print "new output Raster: " + raster
ascii = asciiList.reset()</p>

<h1>remove geoprocessor object from memory</h1>

<p>del gp</p>
]]></content>
  </entry>
  
</feed>
