<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Web-GIS | mattmakesmaps]]></title>
  <link href="http://mkgeomatics.github.io/blog/categories/web-gis/atom.xml" rel="self"/>
  <link href="http://mkgeomatics.github.io/"/>
  <updated>2013-04-28T11:33:16-07:00</updated>
  <id>http://mkgeomatics.github.io/</id>
  <author>
    <name><![CDATA[Matthew Kenny]]></name>
    <email><![CDATA[matthewkenny AT gmail DOT com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[GeoDjango: Standing Up A GeoJSON Web-Service]]></title>
    <link href="http://mkgeomatics.github.io/blog/2011/12/12/geodjango-standing-up-a-geojson-web-service/"/>
    <updated>2011-12-12T00:30:17-08:00</updated>
    <id>http://mkgeomatics.github.io/blog/2011/12/12/geodjango-standing-up-a-geojson-web-service</id>
    <content type="html"><![CDATA[<p>The models are complete. The database is loaded with some test tabular and spatial data. We're pushing out HTML representations of attribute data using GeoDjango's standard templating functions. Now, the focus moves to visualizing these features' geometries in a spatial context. Just as with a Django QuerySet, GeoDjango provides a GeoQuerySet. <!-- more --> When paired with a spatially-enabled database (e.g. PostGIS, SpatialLite, etc.), the GeoQuerySet provides functionality for querying data using a series of spatial filters, in addition to tabular filters. As a point of reference, the GeoDjango docs have great tables depicting a blow-by-blow comparison of different spatial databases, displaying each available <a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/db-api/#spatial-lookup-compatibility">Spatial Lookup</a> and <a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/db-api/#geoqueryset-methods">GeoQuerySet method</a>. Take note, PostGIS is the clear winner in terms of functionality ;)</p>

<h2>Why GeoJSON?</h2>

<p>From the perspective of exporting data, GeoDjango supports a number of formats. The GeoQuerySet methods can represent your model's geometry column in a number of different <a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/geoquerysets/#geometry-output">formats</a>: GeoHash, GeoJSON, GML, KML, and SVG. Of all these serialization formats, I've found KML to be the most frequently used amongst GeoDjango users. Illustrative of this, three of the four functions in <a href="https://code.djangoproject.com/browser/django/trunk/django/contrib/gis/shortcuts.py">django.contrib.gis.shortcuts</a> have to do with KML/KMZ. That's awesome, but where is the love for GeoJSON?</p>

<p>KML can be easily consumed by OpenLayers, the king of open source web mapping viewers. But some of the new kids, e.g. leaflet, polymaps, look to favor GeoJSON over KML as an input for dynamically rendered data, not directly consuming KML out-of-the-box. That being said, if you want KML, this <a href="https://github.com/shramov/Leaflet/tree/master/src/layer">fork of leaflet</a> looks like it will work for you. In my particular project, I'm interested in using leaflet, so GeoJSON was the way to go.</p>

<p>Later on, I'd like to do some speed comparisons, rendering the same featureset using OpenLayers, represented as both KML and GeoJSON, but that's for the future. I'm wondering if OpenLayers will handle the JSON object faster then KML's XML? JSON is just JavaScript after all.</p>

<h2>The Problem</h2>

<p>The GeoDjango GeoQuerySet API has built in methods to handle the serialization and de-serialization of a result set's geometries into different formats. The problem is that these methods only wrap the geometries of a result set. For display in a web mapping application, like leaflet, I want to have access to both the geometry in the format of my choosing, as well as the supplementary attributes (name, type, etc.) which provide context for that geometry.</p>

<p>For example, asking for the GeoJSON representation of a given feature through Django's shell, like this:</p>

<p>``` python</p>

<h1>Import Models from the Company Application</h1>

<p>from company.Models import *</p>

<h1>Create a GeoQuerySet from the primary key, return GeoJSON</h1>

<p>qs = Boundary.objects.filter(pk=1).geojson()</p>

<h1>Print GeoJSON representation of geom</h1>

<p>print qs[0].geojson
```</p>

<p>Will produce a GeoJSON object like this:</p>

<p>``` javascript
{
 "type":"MultiPolygon",
  "coordinates":[</p>

<pre><code>[
  [
    [
      -122.574295,
      47.856636
    ],
    [
      -122.573924,
      47.85718
    ],
    [
      -122.573719,
      47.85757
    ] // Truncated Verticies
  ]
]
</code></pre>

<p>  ]
}
```</p>

<p>As shown in the example above, the geometries are returned, but not the tabular attributes associated with that feature. Looking at the <a href="http://geojson.org/geojson-spec.html">GeoJSON spec</a>, there are multiple 'type' values which an object can be constrained by. Using GeoDjango's geoJSON() method will produce a type matching the geometry listed in the associated GeoDjango model (point, line, polygon, etc). The distinction here is that I'd like to return a GeoJSON object of type 'Feature' or 'FeatureCollection'. These types require an additional 'properties' parameter, which can store tabular attributes. From the spec:</p>

<blockquote><p>A feature object must have a member with the name "properties". The value of the properties member is an object (any JSON object or a JSON null value).</p></blockquote>

<p>So, the trick now is to dynamically create a GeoJSON object which contains both populated Geom and Properties attributes.</p>

<h2>The fix (vectorformats)</h2>

<p>In order to create a fully populated GeoJSON object, we need to bring in some extra assistance. Some quick searching brought me to this stack exchange <a href="http://stackoverflow.com/questions/3034482/rendering-spatial-data-of-geoqueryset-in-a-custom-view-on-geodjango">response</a>, from <a href="http://crschmidt.net/blog/">Chris Schmidt</a>. Chris' vectorformats package handles the serialization and de-serializtion of a variety of formats, including Django Querysets and GeoJSON. From the project <a href="http://packages.python.org/vectorformats/">homepage</a>:</p>

<blockquote><p>The vectorformats library is designed to make it easy to serialize content from any source to any source within Python. Think of it as a “poor man’s OGR” – a pure Python implementation of transforming features to and from various formats (largely XML based).</p></blockquote>

<p>Installing vectorformats is as easy as:</p>

<p><code>bash
$sudo easy_install vectorformats
</code></p>

<p>From there, as outlined in the above referenced post, it's only a matter of adding a few lines into your GeoDjango app's <a href="https://github.com/mattmakesmaps/geodjango/blob/master/sampling/views.py">view function</a>.</p>

<p>``` python</p>

<h1>Using vectorfeatures module return a GeoJSON FeatureCollection</h1>

<h1>for a given boundary ID.</h1>

<p>def boundary_detail(request, boundary_id):</p>

<pre><code>boundary_detail = Boundary.objects.filter(pk=boundary_id)
djf = Django.Django(geodjango='geom', properties=['name'])
geoj = GeoJSON.GeoJSON()
s = geoj.encode(djf.decode(boundary_detail))
return HttpResponse(s)
</code></pre>

<p>```</p>

<p>The resulting GeoJSON object, represented as a 'type' of 'FeatureCollection':</p>

<p>``` javascript
{
  "crs":null,
  "type":"FeatureCollection",
  "features":[</p>

<pre><code>{
  "geometry":{
    "type":"MultiPolygon",
    "coordinates":[
      [
        [
          [
            -122.574295,
            47.856636
          ],
          [
            -122.573924,
            47.85718
          ],
          [
            -122.573719,
            47.85757
          ] // Truncated Verticies
        ]
      ]
    ]
  },
  "type":"Feature",
  "id":1,
  "properties":{
    "name":"Port Gamble"
  }
}
</code></pre>

<p>  ]
}
```</p>

<p>And there you have it, GeoJSON containing both the geometry and attributes. This output can now be mapped to URL, creating an endpoint such as 'http://my-site.com/geojson/boundary/{boundary_id}/'. Pass this to your web mapping client, and you're ready to rock.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moving to GeoDjango]]></title>
    <link href="http://mkgeomatics.github.io/blog/2011/11/28/moving-to-geodjango/"/>
    <updated>2011-11-28T00:35:49-08:00</updated>
    <id>http://mkgeomatics.github.io/blog/2011/11/28/moving-to-geodjango</id>
    <content type="html"><![CDATA[<p>I've been creating a simple GeoDjango application for managing environmental sampling metadata, and it's been a lot of fun so far. I've had experience working with many different forms of metadata tracking, from spreadsheets, to wikis, to online project management tools. All of them have their ups and downs, and it seems like there is always a dealbreaker with each organizational method.</p>

<p>Spreadsheets are easy to edit, but lack any form of relational structure (two sets of data for the same report? i guess i'll just put two entries into the same cell).</p>

<!-- more -->


<p>[caption id="attachment_487" align="alignnone" width="464" caption="sometimes spreadsheets just don't work..."]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot.png" alt="" /></a>[/caption]</p>

<p>Wikis are cool, allow easy access to information, but are (in certain cases) a pain for folks to edit. Take the experience of table creation. Dokuwiki, a generic wiki software, requires a series of  carefully placed carrots and pipes to delineate headers and columns. A common pain comes when adding a new value to a new row, in which that value exceeds the length of any previous cell. This requires the author to expand the column header, and all previously entered rows, re-aligning the pipes and carrots. Granted as a slightly OCD GIS Analyst, the sight of a well crafted text table fills me with no less wonder then when I saw Albert Bierstadt's <a href="http://www.seattleartmuseum.org/exhibit/exhibitDetail.asp?eventID=21084">"Puget Sound on the Pacific Coast"</a>, but it's just darn tedious at times. Additionally, as the log of sampling events grows larger, it gets harder to manage. Dokuwiki, AFAIK provides no ways to automatically resort entire sections of pages or records in tables based on alphabetical order, which would make searching for information on a particular page much faster as content becomes larger and larger.</p>

<p><code>
^ Column One                ^ Column Two                 ^
| Zee 'z' string            | This is a longer string    |
| 2nd longer string of text | 2nd short string           |
| SuperShort                | A string starting with 'A' |
</code></p>

<p>Online project management tools are interesting as well. They allow rapid collaboration between project members, and provide template functionality, allowing for status reports on recurring workflows to be easily generated (e.g., create a template for a report, spawn off an instance of a template for each new project). The downside to these services are that: they cost money, they also may not provide a normalized way to store data, and (of most interest to myself) they probably don't allow for the storage/visualization of spatial data.</p>

<p>[caption id="attachment_488" align="alignnone" width="300" caption="10 megs free for one user? cool!"]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-1.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-1-300x162.png" alt="" /></a>[/caption]</p>

<p>In comes GeoDjango. Over the next few posts, I think I'll record my experiences developing an application that allows the storage of metadata, within the context of environmental sampling efforts. The goal is to provide a web application which stores both tabular and spatial data in a normalized fashion, and easily visualize both in an informative way.</p>

<p>[caption id="attachment_489" align="alignnone" width="300" caption="Hey look Ma', it's GeoJSON!"]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-2.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-2-300x147.png" alt="" /></a>[/caption]</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hand-Rolled Vector Tiles - TileStache]]></title>
    <link href="http://mkgeomatics.github.io/blog/2011/02/25/hand-rolled-vector-tiles-tilestache/"/>
    <updated>2011-02-25T05:09:52-08:00</updated>
    <id>http://mkgeomatics.github.io/blog/2011/02/25/hand-rolled-vector-tiles-tilestache</id>
    <content type="html"><![CDATA[<p>A few weeks ago I found myself surfing the intertubes for instructions on how to serve up some vector tile goodness. That search came up pretty much empty, except for one glimmering <a href="http://gis.stackexchange.com/questions/3712/create-vector-geojson-tiles-for-polymaps">thread</a> of hope. The answer, <a href="http://tilestache.org/">TileStache</a> { &lt;-- Imagine that's a mustache on it's side.</p>

<blockquote><p>TileStache is a Python-based server application that can serve up map tiles based on rendered geographic data.</p></blockquote>

<!-- more -->


<p>By design, TileStache can be used to serve up stylish TMS tiles using <a href="http://mapnik.org/">mapnik</a> map files, and can also be used to locally cache remote-services via <a href="http://tilestache.org/doc/#providers">proxy</a>. What I'm most interested in though, is it's ability to deploy vector tiles. So what are vector tiles? Think TMS tiles... but replace representations of the geometries through images, with <a href="http://geojson.org/">GeoJSON</a>. Pretty wild right? Specifically, the TileStache <a href="http://tilestache.org/doc/TileStache.Goodies.Providers.PostGeoJSON.html">PostGeoJSON Provider</a> can be used to connect TileStache to a PostGIS data source, and return a tile comprised entirely of GeoJSON data.</p>

<p>For example, data from a PostGIS data source can be rendered as an image tile (.../10/16/357.png), like this:</p>

<p><a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/tile.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/tile.png" alt="" /></a></p>

<p>But can also be represtented as a vector tile (.../10/16/357.json), like this:</p>

<p>``` javascript
// Subset of a single 256x256 pixel vector tile.
{
  "type": "FeatureCollection",
  "features": [</p>

<pre><code>{
  "geometry": {
    "type": "MultiPolygon",
    "coordinates": [
      [
        [
          [
            -122.973093,
            47.969842
          ],...
          [
            -122.973093,
            47.969842
          ]
        ]
      ]
    ]
  },
  "type": "Feature",
  "properties": {
    "property_s": "USFS",
    "juris_name": "Olympic National Forest"
  },
  "id": 1280
}
</code></pre>

<p>  ]
}
```</p>

<p>So what are the advantages of using vector tiles? You can already use <a href="http://dev.openlayers.org/docs/files/OpenLayers/Format/GeoJSON-js.html">OpenLayers' GeoJSON</a> format reader to populate a vector layer in OL. It's an issue of size. Highly complex geometries can be large in size, and requesting all that data at once can be time consuming. Vector tiles approach this problem using the same answer as TMS... only request those sections of data which you need at that time. By only requesting those tiles within the user's current extent + a small buffer, the need to download large geometries at once can be negated. Furthermore, just as TMS's can be pre-cached to disk (seeded), so can vector tiles.</p>

<p>One example of this is serving up a combined NFS boundary dataset compiled by my good pal, Greg (<a href="http://www.chopshopgeo.com/blog/">http://www.chopshopgeo.com/blog/</a>). These boundaries are <strong>dense</strong> and displaying them at their full extent &amp; raw level of detail is expensive. But by breaking the vector representations of these geometries up into a standard tile scheme, only those tiles which we need are requested, and only when we need them. As a side note, in addition to tiling, I also simplified the boundaries, to promote faster load time at small-scales. The least granular vector representations display at the smallest zoom-scales, while the highest (raw, unsimplified) level of granularity displays only at the largest zoom-scales.</p>

<p>[caption id="attachment_398" align="alignnone" width="665" caption="NFS Boundaries Provided By ChopShopGeo"]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/parks.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/parks.png" alt="" /></a>[/caption]</p>

<p>Additionally, using vector representations of geometry rather then cached images allows styling of those geometries on the fly. <a href="http://polymaps.org/">Polymaps</a>, the only display client I've found so far that can consume vector tiles out-of-the-box, renders these tiles as SVG elements. Because of this, unique styling can be applied via CSS; controlling the color, stroke, fill, etc. of each geometry in response to both attributes associated with the geometry (see image below) or user input... ala the <a href="http://polymaps.org/ex/statehood.html">Polymaps example page</a>.</p>

<p>[caption id="attachment_393" align="alignnone" width="691" caption="USGS real-time gauge stations. Darker dots represent stronger streamflow, lighter dots represent slower flow. You'll have to ignore the fact that I'm symbolizing streamflow without the streams."]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/usgs.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/usgs.png" alt="" /></a>[/caption]</p>

<p>The above example converts data from the <a href="http://waterservices.usgs.gov/rest/WOF-IV-Service.html">USGS Instantaneous Values Web Service</a> (part of the <a href="http://waterdata.usgs.gov/nwis/">USGS Water Date for the Nation program</a>) as a JSON response to GeoJSON. These data points are then symbolized dynamically using Polymaps. More on that later.</p>

<p><code>javascript
{
"type": "FeatureCollection",
"features": [{
"geometry": {
"type": "MultiPolygon",
"coordinates": [
[
[
[-122.973093, 47.969842],
[-122.973093, 47.969842]
]
]
]
},
http: //jsbeautifier.org/
"type": "Feature",
"properties": {
"property_s": "USFS",
"juris_name": "Olympic National Forest"
},
"id": 1280
}]
}
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cURL'ing to FeatureServer from PostGIS: Easier then I Thought]]></title>
    <link href="http://mkgeomatics.github.io/blog/2010/07/09/curling-to-featureserver-from-postgis-easier-then-i-thought/"/>
    <updated>2010-07-09T05:25:40-07:00</updated>
    <id>http://mkgeomatics.github.io/blog/2010/07/09/curling-to-featureserver-from-postgis-easier-then-i-thought</id>
    <content type="html"><![CDATA[<p>So I've finished cutting a draft tileset using mapnik, <a href="http://mkgeomatics.com/apps/bus/bus.html">depicting bus routes in Bellingham, WA</a>. Now that the cartography is well in progress, I'd like to add some interactivity to the map. My first attempt at this will be to utilize MetaCarta (Chris Schmidt)'s <a href="http://featureserver.org/">FeatureServer</a>. FeatureServer allows one to use standard HTTP verbs to GET representations of data, POST new data, or DELETE existing data. While querying data you can also pass additional URL parameters like a bounding box or attribute to select out a smaller subset of returned representations. I'll be POST'ing a bus stop dataset to FeatureServer as GeoJSON. Once the data are stored in FeatureServer, I'll be able to add popups based on a user's click of a bus stop.</p>

<p>Getting data stored on my local PostGIS install to my remote FeatureServer instance turned out to be a three step process.</p>

<p><strong>Step One:</strong> Convert local PostGIS bus stops layer to GeoJSON via OGR</p>

<p>I had originally planned on writing a pg/plsql function to try and output a bash script. The script would cURL each feature individually to my FeatureServer instance. This proved to be way more work then I had expected. What was the solution? <a href="http://www.gdal.org/ogr/">OGR</a>, of course. OGR has read/write drivers for both <a href="http://www.gdal.org/ogr/drv_geojson.html">GeoJSON</a> and <a href="http://www.gdal.org/ogr/drv_pg.html">PostGIS</a>. This allows one to convert an entire dataset to GeoJSON with a single command (see below).</p>

<p>[sourcecode language="bash"]
ogr2ogr -f "GeoJSON" ogrstops.json PG:"host=localhost dbname=routing user=postgres password=*** port=5432" "wtastops(the_geom)"
[/sourcecode]</p>

<p><strong>Step 2:</strong> Wrap "coordinate" elements in double brackets</p>

<p>When initially trying to cURL the GeoJSON output to FeatureServer, I was receiving an error stating that a bounding box could not be determined for the first geometry in my dataset. After some trial-and-error, I soon realized that the OGR output FeatureCollection was wrapping each point feature's geometry in a single set of brackets. This type of behavior follows the GeoJSON <a href="http://geojson.org/geojson-spec.html#id9">specification for a FeatureCollection</a>, as far as I can tell. However, in order for FeatureServer to consume this dataset, each point feature is required to be wrapped in a second set of brackets. I used gedit to run the find/replace. Below is an example of a GeoJSON feature which FeatureServer can consume. This individual feature is part of a larger FeatureCollection.</p>

<p>[sourcecode language="js"]</p>

<p>{ "type": "Feature",</p>

<pre><code>      "properties": {
         "POINT_ID": "1000",
         "POINT_NAME": "Fielding at 32nd",
         "SHELTER": "Yes", "BENCH": "No" },
      "geometry": {
         "type": "Point",
         "coordinates": [[-122.474490,48.730021]]}
</code></pre>

<p>}
[/sourcecode]</p>

<p><strong>Step 3:</strong> cURL GeoJSON to FeatureServer</p>

<p>The last step is to actually POST the data to FeatureServer. For that, I used cURL.</p>

<p>[sourcecode language="bash"]</p>

<p>curl -d @ogrstops.json http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/create.json</p>

<p>[/sourcecode]</p>

<p>Now that the features have been uploaded, we can view them via FeatureServer as <a href="http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.georss">GeoRSS</a>, <a href="http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.kml">KML</a>, <a href="http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.json">JSON</a>, <a href="http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.gml">GML</a>. Neat!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[pgRouting III: PHP + OpenLayers Interface]]></title>
    <link href="http://mkgeomatics.github.io/blog/2010/02/06/pgrouting-iii-php-openlayers-interface/"/>
    <updated>2010-02-06T09:47:11-08:00</updated>
    <id>http://mkgeomatics.github.io/blog/2010/02/06/pgrouting-iii-php-openlayers-interface</id>
    <content type="html"><![CDATA[<p>With the routing <a href="http://www.mkgeomatics.com/wordpress/?p=312">database configured and populated</a>, and with <a href="http://www.mkgeomatics.com/wordpress/?p=322">geoserver rendering the WMS</a>, now the focus can shift on designing the actual display and functionality.</p>

<p>The conceptual plan is as follows:</p>

<ul>
<li><p>Extract the geometry of a user's click on the map.</p></li>
<li><p>Pass the extracted geometry to a PHP script, via an HTTP GET request.</p></li>
<li><p>Use the PHP script to pass the geometry as part of an SQL query against the PostGIS/pgRouting database.</p></li>
<li><p>Return the geometry from the database as <a href="http://geojson.org/">GeoJSON</a>, and deserialize it into an OpenLayers vector layer feature.</p></li>
</ul>


<p>The code to extract a user's clicked coordinates was taken from <a href="http://openlayers.org/dev/examples/click.html">this</a> OpenLayers example. It was then modified to pass the xy coordinates to a second function, designed to create a URL which will execute a PHP script.</p>

<p>[sourcecode language="javascript"]trigger: function(e) {
 var xy = map.getLonLatFromViewPortPx(e.xy);
 executeSQL(xy);
 }[/sourcecode]</p>

<p>Passing the XY variable to the executeSQL() function, we are able to now seperate out the individual X and Y coordinates, and apply them to their respective parameters in our URL string.</p>

<p>[sourcecode language="javascript"]// Build the URL
 var json_url = "http://localhost/near_vertex_astar.php?";
 json_url += "x=" + escape(xy.lon);
 json_url += "&amp;y=" + escape(xy.lat);[/sourcecode]</p>

<p>Having constructed the URL, we are now ready to use it to populate an OpenLayers vector layer with data.</p>

<p>[sourcecode language="javascript"]// Make a fresh vector layer, pulling features from our script URL
 json_layer = new OpenLayers.Layer.Vector("GeoJSON", {
 styleMap: myStyles,
 strategies: [new OpenLayers.Strategy.Fixed()],
 protocol: new OpenLayers.Protocol.HTTP({
 url: json_url,
 format: new OpenLayers.Format.GeoJSON()
 })
 });[/sourcecode]</p>

<p>Alright! So where are we at right now? A user has clicked the map, and that click's geometry has been extracted and sent to a PHP script on the server for further work. The PHP script will execute SQL in the PostGIS/pgRouting data base to do the following:</p>

<ul>
<li><p>Find the closest vertex in our routing network to the user's map click. This will be used as a source vertex.</p></li>
<li><p>Find all firestations within 5km of the vertex (which have been pre-attributed with the closest vertex on the routing network to their location).</p></li>
<li><p>Calculate the cost (as defined by total length of the route) from the source vertex to each fire station (really the routing network vertex).</p></li>
<li><p>Return back as GeoJSON only the geometry for the route with the lowest cost.</p></li>
</ul>


<p>Why all the hassle with determining the cost? Can't you just use PostGIS' ST_DWithin() function to find the closet firestation to our user's click and create the route? Well you could, but it might not always be the shortest route.</p>

<p>[caption id="attachment_339" align="alignnone" width="300" caption="Euclidean distance versus Manhattan. Which one is shorter?"]<a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/distance.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/distance-300x279.png" alt="Euclidean distance versus Manhattan. Which one is shorter?" /></a>[/caption]</p>

<p>This behavior can be respresented in the routing network with the example below. Two different routes are generated from the same source vertex based on the combination of routing algorithm and account for route cost. On the left, the <a href="http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">dijkstra algorithm</a> is used to return the route to the closest fire station as the result of an ST_DWithin() query. On the right, the A-Star algorithm is used, and the route costs of all fire stations within a buffer are taken into account. As we can see, a different route and a different station are returned.</p>

<p><a href="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/dj_left_astar_right1.png"><img src="http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/dj_left_astar_right1-1024x338.png" alt="Comparing the two search algorithms and cost relationships." /></a></p>

<p>A link to the JS and PHP scripts can be found at the end of this post. This definitely is not the most elegant solution to working with routing, but in terms of an experiment it was a great learning exercise. I'm really excited to dive deeper into PostGIS and pgRouting. The next step in the process will be incorporating OSM data, and adding in addition attributes which affect cost (speed limits, one-way streets, etc).</p>

<p>View the <a href="http://mkgeomatics.com/apps/syntaxhighlighter/astar_php.html">PHP</a>.</p>

<p>View the <a href="http://mkgeomatics.com/apps/syntaxhighlighter/astar.html">OL JS</a>.</p>
]]></content>
  </entry>
  
</feed>
